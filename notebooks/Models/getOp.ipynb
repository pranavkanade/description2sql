{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.consts import *\n",
    "\n",
    "from utils.utilities import (\n",
    "    test, show_dep, get_data, get_nominal_subjects, get_prep, get_objects, get_root, _is_verb, get_aux,\n",
    "    check_if_wh, get_csubj, get_amod, get_actual_subtree_for_finding_agg, get_subtree_list)\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# nlp_pipe = spacy.load('en_core_web_lg')\n",
    "PIPE = spacy.load('en_coref_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = ['dev', 'test', 'train']\n",
    "\n",
    "data_path = \"./data/%s_dataset.json\"\n",
    "x_file = './op_data1/%s_op_X.pkl'\n",
    "y_file = './op_data1/%s_op_Y.pkl'\n",
    "idx_file = './op_data1/%s_op_idx.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vdata:\n",
    "    def __init__(self):\n",
    "        self.agg_X = list()\n",
    "        self.agg_Y = list()\n",
    "        self.agg_IDX = list()\n",
    "\n",
    "    def fill_data(self, act_adjs, act_op, idx):\n",
    "        temp_x = np.array([])\n",
    "        temp_y = np.array([])\n",
    "        if act_adjs is not None and len(act_adjs) > 0 and act_op in cond_ops:\n",
    "    #         print(\"idx : %d\"%idx)\n",
    "            if len(act_adjs) > 4:\n",
    "                act_adjs = act_adjs[:4]\n",
    "            for tok in act_adjs:\n",
    "                if tok.has_vector:\n",
    "                    temp_x = np.append(temp_x, tok.vector)\n",
    "            temp_y = (cond_funcs == act_op).astype(np.float)\n",
    "        else:\n",
    "            temp_x = np.zeros((X_size))\n",
    "            temp_y = (cond_funcs == \"OP\").astype(np.float)\n",
    "        if temp_x.size < X_size:\n",
    "            temp_x = np.append(temp_x, np.zeros((X_size - temp_x.size)))\n",
    "    #     print(\"fill data : \")\n",
    "    #     print(temp_y)\n",
    "\n",
    "        self.agg_X.append(temp_x)\n",
    "        self.agg_Y.append(temp_y)\n",
    "        self.agg_IDX.append(idx)\n",
    "\n",
    "    def dump_data(self, dt):\n",
    "        v_x = np.array(self.agg_X)\n",
    "        v_y = np.array(self.agg_Y)\n",
    "        v_idx = np.array(self.agg_IDX)\n",
    "\n",
    "        with open(x_file%dt, 'wb') as fx:\n",
    "            pickle.dump(v_x, fx)\n",
    "\n",
    "        with open(y_file%dt, 'wb') as fy:\n",
    "            pickle.dump(v_y, fy)\n",
    "\n",
    "        with open(idx_file%dt, 'wb') as fidx:\n",
    "            pickle.dump(v_idx, fidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_size = 1200\n",
    "agg_X = list()\n",
    "agg_Y = list()\n",
    "agg_IDX = list()\n",
    "cond_funcs = np.array(cond_ops)\n",
    "\n",
    "def refresh_globals():\n",
    "    agg_X = list()\n",
    "    agg_Y = list()\n",
    "    agg_IDX = list()\n",
    "\n",
    "def fill_data(act_adjs, act_op, idx):\n",
    "    temp_x = np.array([])\n",
    "    temp_y = np.array([])\n",
    "    if act_adjs is not None and len(act_adjs) > 0 and act_op in cond_ops:\n",
    "#         print(\"idx : %d\"%idx)\n",
    "        if len(act_adjs) > 4:\n",
    "            act_adjs = act_adjs[:4]\n",
    "        for tok in act_adjs:\n",
    "            if tok.has_vector:\n",
    "                temp_x = np.append(temp_x, tok.vector)\n",
    "        temp_y = (cond_funcs == act_op).astype(np.float)\n",
    "    else:\n",
    "        temp_x = np.zeros((X_size))\n",
    "        temp_y = (cond_funcs == \"OP\").astype(np.float)\n",
    "    if temp_x.size < X_size:\n",
    "        temp_x = np.append(temp_x, np.zeros((X_size - temp_x.size)))\n",
    "#     print(\"fill data : \")\n",
    "#     print(temp_y)\n",
    "    \n",
    "    agg_X.append(temp_x)\n",
    "    agg_Y.append(temp_y)\n",
    "    agg_IDX.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_and_subj_pair(data_sample):\n",
    "#     print(\"\\n========================================================\\n\")\n",
    "#     pprint(data_sample)\n",
    "    # get the doc representation of the string\n",
    "    doc = PIPE(data_sample['question'])\n",
    "    # Find out the root of the given statement\n",
    "    root = get_root(doc)\n",
    "#     import pdb; pdb.set_trace()\n",
    "    is_verb = _is_verb(root)\n",
    "    aux = None\n",
    "#     if not is_verb:\n",
    "        # Some times the root can be a noun, in that case it'll always be associated to\n",
    "        # an aux verb, and we gotta find it\n",
    "    aux = get_aux(root)\n",
    "    # If there is any aux found, we use it as our verb root\n",
    "    if aux is not None and len(aux) > 0:\n",
    "        root_verb = aux[0]\n",
    "    else:\n",
    "        # Else, we use our root as it is\n",
    "        root_verb = root\n",
    "    # Check if there is any csubj attached this means we have two wh nouns attached to\n",
    "    # two different verbs one is asking and other qualifying.\n",
    "    csubj_verb = get_csubj(root_verb)\n",
    "    if csubj_verb is not None:\n",
    "        root_verb = csubj_verb\n",
    "#     print(\"ROOT : {}\".format(root.text))\n",
    "#     print(\"AUX : \")\n",
    "#     pprint(aux)\n",
    "    # nominals in this case is going to be a list of all the cols\n",
    "    # in SELECT clause. If we find any nsubj attached to the root_verb we catch it here.\n",
    "    nominals = get_nominal_subjects(root_verb)\n",
    "    is_wh = False\n",
    "    # If what we have found is not actually a noun but a question noun (wh-word)\n",
    "    # TODO: In this case we may want to go on hunt for the actual nominal col.\n",
    "    if len(nominals) != 0:\n",
    "        is_wh = check_if_wh(nominals)\n",
    "    if is_wh:\n",
    "        # for now\n",
    "        pass\n",
    "#     print(\"SUBJ : \")\n",
    "#     pprint(nominals)\n",
    "    # Even after all this if there is no way the prog have found a nominal\n",
    "    # find out if there is any prop attached to the verb.\n",
    "    # If there is then we may look for prep_obj attached to it for the nominal.\n",
    "    prep = None\n",
    "    if len(nominals) == 0:\n",
    "        prep = get_prep(root_verb)\n",
    "#     print(\"PREP : \")\n",
    "#     pprint(prep)\n",
    "    pobj = None\n",
    "    if prep is not None:\n",
    "        pobj = get_objects(prep)\n",
    "        nominals.append(pobj)\n",
    "#     print(\"POBJ : \")\n",
    "#     pprint(pobj)\n",
    "#     show_dep(doc)\n",
    "    return nominals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs_other_than_root(doc):\n",
    "    verbs = list()\n",
    "    o_verbs = list()\n",
    "    root = get_root(doc)\n",
    "    for tok in doc:\n",
    "        if tok.pos_ in VERB and tok.idx != root.idx:\n",
    "            o_verbs.append(tok)\n",
    "        elif tok.pos_ in VERB:\n",
    "            verbs.append(tok)\n",
    "#         print(tok.text, tok.pos_)\n",
    "    return verbs, o_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJECTIVES = [\"amod\", \"acomp\"]\n",
    "\n",
    "def get_amod_n_acomp_for_verbs(vb):\n",
    "    st = get_subtree_list(vb)\n",
    "    mods = list()\n",
    "    for each_tok in st:\n",
    "        if each_tok.dep_ in ADJECTIVES:\n",
    "            mods.append(each_tok)\n",
    "            \n",
    "    return mods\n",
    "\n",
    "def get_op_mods(vb_list):\n",
    "    op_mods = list()\n",
    "    for each_vb in vb_list:\n",
    "        op_mods.extend(get_amod_n_acomp_for_verbs(each_vb))\n",
    "    return op_mods\n",
    "\n",
    "def get_all_op_mods(r_verbs, o_verbs):\n",
    "    all_op_mods = list()\n",
    "    o_op_mods = get_op_mods(o_verbs)\n",
    "    all_op_mods.extend(o_op_mods[::-1])\n",
    "    if len(all_op_mods) == 0:\n",
    "        r_op_mods = get_op_mods(r_verbs)\n",
    "        all_op_mods.extend(r_op_mods[::-1])\n",
    "    return all_op_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_params(conds, r_verbs, o_verbs, all_op_mods):\n",
    "    if len(conds) == 0:\n",
    "        OP = 'OP'\n",
    "    else:\n",
    "        OP = conds[0][1]\n",
    "        \n",
    "    all_op_mods.extend(r_verbs)\n",
    "    all_op_mods.extend(o_verbs)\n",
    "#     pprint(all_op_mods)\n",
    "#     print(OP)\n",
    "    if len(all_op_mods) > 4:\n",
    "        all_op_mods[:4]\n",
    "    return all_op_mods, OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data(dt):\n",
    "    v_x = np.array(agg_X)\n",
    "    v_y = np.array(agg_Y)\n",
    "    v_idx = np.array(agg_IDX)\n",
    "\n",
    "    with open(x_file%dt, 'wb') as fx:\n",
    "        pickle.dump(v_x, fx)\n",
    "\n",
    "    with open(y_file%dt, 'wb') as fy:\n",
    "        pickle.dump(v_y, fy)\n",
    "    \n",
    "    with open(idx_file%dt, 'wb') as fidx:\n",
    "        pickle.dump(v_idx, fidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dt, vd):\n",
    "    refresh_globals()\n",
    "    print(\"Data type : \", dt)\n",
    "    data = get_data(data_path%dt)\n",
    "    print(\"DATA : \", len(data))\n",
    "    count = 0\n",
    "    for idx in range(len(data)):\n",
    "    # idx = -1\n",
    "    # while count  30:\n",
    "    #     idx += 1\n",
    "        conds = data[idx]['sql']['conds']\n",
    "        try:\n",
    "    #         if conds[0][1] == \"=\":\n",
    "    #             continue\n",
    "            subjs = get_verb_and_subj_pair(data[idx])\n",
    "#             print(\"\\n========================================================\\n\")\n",
    "    #         pprint(data[idx]['question'])\n",
    "    #         show_dep(PIPE(data[idx]['question']))\n",
    "    #         print(\"SUBJs : \")\n",
    "    #         pprint(subjs)\n",
    "    #         print(\"SELECT : \")\n",
    "    #         pprint(data[idx]['sql']['sel'])\n",
    "    #         print(\"CONDS : \", conds)\n",
    "            verbs, o_verbs = get_verbs_other_than_root(PIPE(data[idx]['question']))\n",
    "#             print(\"VERBS : \")\n",
    "#             pprint(verbs)\n",
    "#             print(\"OTHER VERBS : \")\n",
    "#             pprint(o_verbs)\n",
    "#             print(\"test1\")\n",
    "            all_op_mods = get_all_op_mods(verbs, o_verbs)\n",
    "#             print(all_op_mods)\n",
    "#             print(\"test2\")\n",
    "            act_adjs, cond_op = get_actual_params(conds, verbs, o_verbs, all_op_mods)\n",
    "#             print(\"test3\")\n",
    "#             pprint(act_adjs)\n",
    "#             print(cond_op)\n",
    "            vd.fill_data(act_adjs, cond_op, idx)\n",
    "            count += 1\n",
    "        except Exception:\n",
    "    #         amod = get_amod(PIPE(data[idx]['question']))\n",
    "    #         fill_data(amod, agg_func, idx)\n",
    "            pass\n",
    "\n",
    "    print(\"COUNT : \", count)\n",
    "    #         pprint(data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = vdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd.agg_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type :  dev\n",
      "DATA :  8421\n",
      "COUNT :  8288\n",
      "Data type :  test\n",
      "DATA :  15878\n",
      "COUNT :  15635\n",
      "Data type :  train\n",
      "DATA :  56355\n"
     ]
    }
   ],
   "source": [
    "for dt in data_files:\n",
    "    vd = vdata()\n",
    "    process_data(dt, vd)\n",
    "    vd.dump_data(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sess.run(tf.argmax(output_layer,1), feed_dict={X: [img]})\n",
    "print (\"Prediction for test image:\", np.squeeze(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
